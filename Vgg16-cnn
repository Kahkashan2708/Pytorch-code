{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9243,"sourceType":"datasetVersion","datasetId":2243}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:50:11.036114Z","iopub.execute_input":"2025-10-28T07:50:11.036286Z","iopub.status.idle":"2025-10-28T07:50:12.255177Z","shell.execute_reply.started":"2025-10-28T07:50:11.036269Z","shell.execute_reply":"2025-10-28T07:50:12.254382Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/fashionmnist/t10k-labels-idx1-ubyte\n/kaggle/input/fashionmnist/t10k-images-idx3-ubyte\n/kaggle/input/fashionmnist/fashion-mnist_test.csv\n/kaggle/input/fashionmnist/fashion-mnist_train.csv\n/kaggle/input/fashionmnist/train-labels-idx1-ubyte\n/kaggle/input/fashionmnist/train-images-idx3-ubyte\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:50:12.255901Z","iopub.execute_input":"2025-10-28T07:50:12.256300Z","iopub.status.idle":"2025-10-28T07:50:17.342731Z","shell.execute_reply.started":"2025-10-28T07:50:12.256281Z","shell.execute_reply":"2025-10-28T07:50:17.342013Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"torch.manual_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:50:17.346390Z","iopub.execute_input":"2025-10-28T07:50:17.346923Z","iopub.status.idle":"2025-10-28T07:50:17.356563Z","shell.execute_reply.started":"2025-10-28T07:50:17.346896Z","shell.execute_reply":"2025-10-28T07:50:17.355826Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7d40a6c78db0>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Check for GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:50:19.878689Z","iopub.execute_input":"2025-10-28T07:50:19.879267Z","iopub.status.idle":"2025-10-28T07:50:19.945314Z","shell.execute_reply.started":"2025-10-28T07:50:19.879245Z","shell.execute_reply":"2025-10-28T07:50:19.944528Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_train.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:50:53.580372Z","iopub.execute_input":"2025-10-28T07:50:53.580665Z","iopub.status.idle":"2025-10-28T07:50:58.297378Z","shell.execute_reply.started":"2025-10-28T07:50:53.580647Z","shell.execute_reply":"2025-10-28T07:50:58.296630Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0      2       0       0       0       0       0       0       0       0   \n1      9       0       0       0       0       0       0       0       0   \n2      6       0       0       0       0       0       0       0       5   \n3      0       0       0       0       1       2       0       0       0   \n4      3       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0        30        43         0   \n3       0  ...         3         0         0         0         0         1   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel781  pixel782  pixel783  pixel784  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>pixel784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>43</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:51:11.621617Z","iopub.execute_input":"2025-10-28T07:51:11.621906Z","iopub.status.idle":"2025-10-28T07:51:11.627100Z","shell.execute_reply.started":"2025-10-28T07:51:11.621887Z","shell.execute_reply":"2025-10-28T07:51:11.626515Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(60000, 785)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# train test split\nX = df.iloc[:, 1:].values\ny = df.iloc[:, 0].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:51:26.338386Z","iopub.execute_input":"2025-10-28T07:51:26.338737Z","iopub.status.idle":"2025-10-28T07:51:26.891935Z","shell.execute_reply.started":"2025-10-28T07:51:26.338717Z","shell.execute_reply":"2025-10-28T07:51:26.891230Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# transformations\nfrom torchvision.transforms import transforms\n\ncustom_transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:51:33.900533Z","iopub.execute_input":"2025-10-28T07:51:33.901204Z","iopub.status.idle":"2025-10-28T07:51:37.655358Z","shell.execute_reply.started":"2025-10-28T07:51:33.901184Z","shell.execute_reply":"2025-10-28T07:51:37.654762Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\n\nclass CustomDataset(Dataset):\n\n  def __init__(self, features, labels, transform):\n    self.features = features\n    self.labels = labels\n    self.transform = transform\n\n  def __len__(self):\n    return len(self.features)\n\n  def __getitem__(self, index):\n\n    # resize to (28, 28)\n    image = self.features[index].reshape(28,28)\n\n    # change datatype to np.uint8\n    image = image.astype(np.uint8)\n\n    # change black&white to color -> (H,W,C) -> (C,H,W)\n    image = np.stack([image]*3, axis=-1)\n\n    # convert array to PIL image\n    image = Image.fromarray(image)\n\n    # apply transforms\n    image = self.transform(image)\n\n    # return\n    return image, torch.tensor(self.labels[index], dtype=torch.long)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:51:48.605071Z","iopub.execute_input":"2025-10-28T07:51:48.605507Z","iopub.status.idle":"2025-10-28T07:51:48.611330Z","shell.execute_reply.started":"2025-10-28T07:51:48.605476Z","shell.execute_reply":"2025-10-28T07:51:48.610416Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_dataset = CustomDataset(X_train, y_train, transform=custom_transform)\ntest_dataset = CustomDataset(X_test, y_test, transform=custom_transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:52:04.794840Z","iopub.execute_input":"2025-10-28T07:52:04.795128Z","iopub.status.idle":"2025-10-28T07:52:04.799236Z","shell.execute_reply.started":"2025-10-28T07:52:04.795109Z","shell.execute_reply":"2025-10-28T07:52:04.798471Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:52:14.369228Z","iopub.execute_input":"2025-10-28T07:52:14.370092Z","iopub.status.idle":"2025-10-28T07:52:14.375347Z","shell.execute_reply.started":"2025-10-28T07:52:14.370055Z","shell.execute_reply":"2025-10-28T07:52:14.374597Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Fetch a pretrained model: VGG16","metadata":{}},{"cell_type":"code","source":"import torchvision.models as models\nvgg16 = models.vgg16(pretrained=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:52:41.913070Z","iopub.execute_input":"2025-10-28T07:52:41.913393Z","iopub.status.idle":"2025-10-28T07:52:46.095776Z","shell.execute_reply.started":"2025-10-28T07:52:41.913371Z","shell.execute_reply":"2025-10-28T07:52:46.094891Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 528M/528M [00:02<00:00, 215MB/s] \n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"vgg16","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:53:20.294230Z","iopub.execute_input":"2025-10-28T07:53:20.295080Z","iopub.status.idle":"2025-10-28T07:53:20.300235Z","shell.execute_reply.started":"2025-10-28T07:53:20.295053Z","shell.execute_reply":"2025-10-28T07:53:20.299509Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"vgg16.features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:59:38.045821Z","iopub.execute_input":"2025-10-28T07:59:38.046500Z","iopub.status.idle":"2025-10-28T07:59:38.051442Z","shell.execute_reply.started":"2025-10-28T07:59:38.046474Z","shell.execute_reply":"2025-10-28T07:59:38.050740Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): ReLU(inplace=True)\n  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (3): ReLU(inplace=True)\n  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (6): ReLU(inplace=True)\n  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (8): ReLU(inplace=True)\n  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (11): ReLU(inplace=True)\n  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (13): ReLU(inplace=True)\n  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (15): ReLU(inplace=True)\n  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (18): ReLU(inplace=True)\n  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (20): ReLU(inplace=True)\n  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (22): ReLU(inplace=True)\n  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (25): ReLU(inplace=True)\n  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (27): ReLU(inplace=True)\n  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (29): ReLU(inplace=True)\n  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n)"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"vgg16.classifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:59:10.081712Z","iopub.execute_input":"2025-10-28T07:59:10.082466Z","iopub.status.idle":"2025-10-28T07:59:10.087247Z","shell.execute_reply.started":"2025-10-28T07:59:10.082423Z","shell.execute_reply":"2025-10-28T07:59:10.086507Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Linear(in_features=25088, out_features=1024, bias=True)\n  (1): ReLU()\n  (2): Dropout(p=0.5, inplace=False)\n  (3): Linear(in_features=1024, out_features=512, bias=True)\n  (4): ReLU()\n  (5): Dropout(p=0.5, inplace=False)\n  (6): Linear(in_features=512, out_features=10, bias=True)\n)"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"for param in vgg16.features.parameters():\n  param.requires_grad=False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:53:22.513412Z","iopub.execute_input":"2025-10-28T07:53:22.514160Z","iopub.status.idle":"2025-10-28T07:53:22.517833Z","shell.execute_reply.started":"2025-10-28T07:53:22.514139Z","shell.execute_reply":"2025-10-28T07:53:22.516978Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"vgg16.classifier = nn.Sequential(\n    nn.Linear(25088, 1024),\n    nn.ReLU(),\n    nn.Dropout(0.5),\n    nn.Linear(1024, 512),\n    nn.ReLU(),\n    nn.Dropout(0.5),\n    nn.Linear(512, 10)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:53:40.440572Z","iopub.execute_input":"2025-10-28T07:53:40.441201Z","iopub.status.idle":"2025-10-28T07:53:40.701949Z","shell.execute_reply.started":"2025-10-28T07:53:40.441180Z","shell.execute_reply":"2025-10-28T07:53:40.701326Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"vgg16 = vgg16.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:54:56.954471Z","iopub.execute_input":"2025-10-28T07:54:56.955107Z","iopub.status.idle":"2025-10-28T07:54:57.153216Z","shell.execute_reply.started":"2025-10-28T07:54:56.955085Z","shell.execute_reply":"2025-10-28T07:54:57.152628Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"learning_rate = 0.0001\nepochs = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:55:03.930436Z","iopub.execute_input":"2025-10-28T07:55:03.931147Z","iopub.status.idle":"2025-10-28T07:55:03.934264Z","shell.execute_reply.started":"2025-10-28T07:55:03.931126Z","shell.execute_reply":"2025-10-28T07:55:03.933627Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(vgg16.classifier.parameters(), lr=learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:56:28.750986Z","iopub.execute_input":"2025-10-28T07:56:28.751661Z","iopub.status.idle":"2025-10-28T07:56:28.755643Z","shell.execute_reply.started":"2025-10-28T07:56:28.751636Z","shell.execute_reply":"2025-10-28T07:56:28.754813Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"### Training Loop","metadata":{}},{"cell_type":"code","source":"for epoch in range(epochs):\n  total_epoch_loss = 0\n  for batch_features, batch_labels in train_loader:\n    # move data to gpu\n    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n\n    # forward pass\n    outputs = vgg16(batch_features)\n\n    print(outputs.shape)\n    print(batch_labels.shape)\n\n    # calculate loss\n    loss = criterion(outputs, batch_labels)\n\n    # back pass\n    optimizer.zero_grad()\n    loss.backward()\n\n    # update grads\n    optimizer.step()\n    total_epoch_loss = total_epoch_loss + loss.item()\n    break\n  avg_loss = total_epoch_loss/len(train_loader)\n  print(f'Epoch: {epoch + 1} , Loss: {avg_loss}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:57:32.990991Z","iopub.execute_input":"2025-10-28T07:57:32.991301Z","iopub.status.idle":"2025-10-28T07:57:35.023238Z","shell.execute_reply.started":"2025-10-28T07:57:32.991282Z","shell.execute_reply":"2025-10-28T07:57:35.022506Z"}},"outputs":[{"name":"stdout","text":"torch.Size([32, 10])\ntorch.Size([32])\nEpoch: 1 , Loss: 0.001555045445760091\ntorch.Size([32, 10])\ntorch.Size([32])\nEpoch: 2 , Loss: 0.0015096445083618165\ntorch.Size([32, 10])\ntorch.Size([32])\nEpoch: 3 , Loss: 0.0014576082229614258\ntorch.Size([32, 10])\ntorch.Size([32])\nEpoch: 4 , Loss: 0.001431258201599121\ntorch.Size([32, 10])\ntorch.Size([32])\nEpoch: 5 , Loss: 0.001419669469197591\ntorch.Size([32, 10])\ntorch.Size([32])\nEpoch: 6 , Loss: 0.001359631856282552\ntorch.Size([32, 10])\ntorch.Size([32])\nEpoch: 7 , Loss: 0.0013607722918192546\ntorch.Size([32, 10])\ntorch.Size([32])\nEpoch: 8 , Loss: 0.0012424631118774414\ntorch.Size([32, 10])\ntorch.Size([32])\nEpoch: 9 , Loss: 0.0012754421234130859\ntorch.Size([32, 10])\ntorch.Size([32])\nEpoch: 10 , Loss: 0.0011131020387013754\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"vgg16.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T07:58:05.421565Z","iopub.execute_input":"2025-10-28T07:58:05.421819Z","iopub.status.idle":"2025-10-28T07:58:05.427344Z","shell.execute_reply.started":"2025-10-28T07:58:05.421804Z","shell.execute_reply":"2025-10-28T07:58:05.426763Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=1024, out_features=512, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=512, out_features=10, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"## Evaluate","metadata":{}},{"cell_type":"code","source":"# Evaluate training accuracy\nvgg16.eval() \ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():  \n    for batch_features, batch_labels in train_loader:\n        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n        outputs = vgg16(batch_features)\n        _, predicted = torch.max(outputs, 1)  \n        total += batch_labels.size(0)\n        correct += (predicted == batch_labels).sum().item()\n\ntrain_accuracy = 100 * correct / total\nprint(f\"Epoch: {epoch + 1}, Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\nvgg16.train()  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T08:05:22.890039Z","iopub.execute_input":"2025-10-28T08:05:22.890787Z"}},"outputs":[],"execution_count":null}]}